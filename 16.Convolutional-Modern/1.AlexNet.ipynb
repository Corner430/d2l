{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AlexNet**\n",
    "\n",
    "![AlexNet_Architecture](img/AlexNet_Architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **机器学习**\n",
    "《**Learning with Kernels**》\n",
    "\n",
    "In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory:the Support Vector Machine (SVM).This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs---kernels---for a number of learning tasks.\n",
    "\n",
    "- 特征提取\n",
    "- 选择核函数来计算两个向量之间的相似度\n",
    "- 凸优化问题\n",
    "- 漂亮的定理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **几何学**\n",
    "\n",
    "《**Multiple View Geometry in computer vision**》\n",
    "\n",
    "- 抽取特征\n",
    "- 描述几何（例如多相机）\n",
    "- （非）凸优化\n",
    "- 漂亮定理\n",
    "- 如果假设满足了，效果很好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **特征工程**\n",
    "**opencv**\n",
    "\n",
    "- **特征工程是关键**\n",
    "- 特征描述子：SIFT、SURF\n",
    "- 视觉词袋：K-means聚类\n",
    "- 最后用SVM分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[Hardware](https://www.bilibili.com/video/BV1h54y1L7oe/?share_source=copy_web&vd_source=a7ae9163cb2cd121bfd86ea1f4ecd2ef&t=434)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ImageNet(2010)**\n",
    "\n",
    "| 属性            | 描述                                                                                          |\n",
    "|:----------------:|:-----------------------------------------------------------------------------------------------:|\n",
    "| 名称            | ImageNet 数据集                                                                                |\n",
    "| 类别数目        | 约 1,000 类                                                                                     |\n",
    "| 总图像数目      | 约 1,400,000 张图像                                                                              |\n",
    "| 训练集数量      | 约 1,000,000 张图像                                                                              |\n",
    "| 验证集数量      | 约 50,000 张图像                                                                                 |\n",
    "| 测试集数量      | 约 100,000 张图像                                                                                |\n",
    "| 图像分辨率      | 可变，通常在 224x224 到 400x400 像素之间                                                             |\n",
    "| 数据来源        | 由斯坦福大学创建，从互联网上收集而来的图像数据                                                           |\n",
    "| 用途            | 机器学习和计算机视觉领域的训练和评估，尤其是图像分类和深度学习模型的预训练数据集                              |\n",
    "| 挑战            | 图像类别丰富多样，存在一些难以区分的类别，需要强大的计算资源和优化技术来训练和评估模型                     |\n",
    "| 标注            | 图像都有对应的标签，表示其所属类别                                                                   |\n",
    "| 数据集版本      | ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 是 ImageNet 数据集的一个版本，于 2010 年首次发布 |\n",
    "| 历史和影响      | ImageNet 数据集在计算机视觉社区中推动了深度学习的发展，特别是卷积神经网络（CNNs）的兴起                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 图片 | 自然物体的彩色图片 | 手写数字的黑白图片 |\n",
    "|:---:|:-----:| :-----:|\n",
    "| 大小 |469 x 387 | 28 x 28 |\n",
    "| 样本数 | 1,400,000 | 60,000 |\n",
    "| 类别数 | 1,000 | 10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "- AlexNet赢了2012年 ImageNet 竞赛\n",
    "- 更深更大的 LeNet\n",
    "- 主要改进：\n",
    "  - 丢弃法\n",
    "  - ReLu\n",
    "  - MaxPooling\n",
    "- 计算机视觉方法论的改变"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AlexNet架构**\n",
    "\n",
    "AlexNet使用了8层卷积神经网络\n",
    "\n",
    "AlexNet和LeNet的架构非常相似，如图所示。注意，这里提供的是一个稍微精简版本的AlexNet，去除了当年需要两个小型GPU同时运算的设计特点。\n",
    "\n",
    "![从LeNet（左）到AlexNet（右）](img/alexnet.svg)\n",
    "\n",
    "AlexNet和LeNet的设计理念非常相似，但也存在显著差异。\n",
    "\n",
    "1. AlexNet比相对较小的LeNet5要深得多。AlexNet由八层组成：五个卷积层、两个全连接隐藏层和一个全连接输出层。\n",
    "2. AlexNet使用ReLU而不是sigmoid作为其激活函数。\n",
    "3. AlexNet使用了更大的池化窗口，使用最大池化层\n",
    "4. AlexNet使用了更大的核窗口和步长，因为图片更大了\n",
    "5. AlexNet使用了Dropout来控制全连接层的模型复杂度，防止过拟合。\n",
    "6. **数据增强**：AlexNet在训练时通过从原始图像中**随机截取$224\\times 224$或者其翻转、裁剪、颜色变化**得到$224\\times 224$的图像，**然后再将图像进行标准化处理**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[复杂度](https://www.bilibili.com/video/BV1h54y1L7oe/?share_source=copy_web&vd_source=a7ae9163cb2cd121bfd86ea1f4ecd2ef&t=1852)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **总结**\n",
    "- AlexNet 是更大更深的 LeNet，10x 参数个数，260x 计算复杂度\n",
    "- **新加入了丢弃法，ReLU，最大池化层，和数据增强**\n",
    "- AlexNet赢下了 2012 年 ImageNet 图像识别挑战赛，标志着新的一轮神经网络热潮的开始"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
