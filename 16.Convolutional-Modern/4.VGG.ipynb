{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **使用块的网络VGG**\n",
    "\n",
    "![VGG Architecture](img/VGG_Architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VGG**\n",
    "\n",
    "- AlexNet 比 LeNet 更深更大来得到更好的精度\n",
    "- 能不能更深更大\n",
    "- 选项\n",
    "  - **更多的全连接层（太贵）**\n",
    "  - 更多的卷积层\n",
    "  - **将卷积层组合成块**\n",
    "\n",
    "![从AlexNet到VGG，它们本质上都是块设计](img/vgg.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VGG块**\n",
    "\n",
    "- 深 vs. 宽？\n",
    "  - 5 x 5 卷积\n",
    "  - 3 x 3 卷积\n",
    "  - **深但窄效果更好**\n",
    "- VGG 块\n",
    "  - 3 x 3 卷积（填充 1）（n层，m通道）\n",
    "  - 2 x 2 最大池化层（步幅 2）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VGG架构**\n",
    "- 多个VGG块后接全连接层\n",
    "- **不同次数的重复块得到不同的架构**，VGG-16，VGG-19，...\n",
    "\n",
    "![从AlexNet到VGG，它们本质上都是块设计](img/vgg.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[进度](https://www.bilibili.com/video/BV1Ao4y117Pd/?share_source=copy_web&vd_source=a7ae9163cb2cd121bfd86ea1f4ecd2ef&t=370)**\n",
    "\n",
    "- LeNet(1995)\n",
    "  - 2 卷积 + 池化层\n",
    "  - 2 全连接层\n",
    "- AlexNet(2012)\n",
    "  - 更大更深\n",
    "  - ReLu，Dropout，数据增强\n",
    "- VGG(2014)\n",
    "  - 更大更深的AlexNet（重复的VGG块）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **总结**\n",
    "\n",
    "- VGG使用可重复使用的卷积块来构建深度卷积神经网络\n",
    "- 不同的卷积块个数和超参数可以得到不同复杂度的变种"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
