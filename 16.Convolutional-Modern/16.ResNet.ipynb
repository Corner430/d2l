{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **参数网络（ResNet）**\n",
    "\n",
    "### **加更多的层总是改进精度吗？**\n",
    "\n",
    "![对于非嵌套函数类，较复杂（由较大区域表示）的函数类不能保证更接近“真”函数（ $f^*$ ）。这种现象在嵌套函数类中不会发生。](img/functionclasses.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **残差块**\n",
    "- 串联一个层改变函数类，我们希望能**扩大函数类**\n",
    "- 残差块加入快速通道（右边）来得到 $f(x) = x + g(x)$ 的结构\n",
    "\n",
    "![一个正常块（左图）和一个残差块（右图）。](img/residual-block.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ResNet 块细节**\n",
    "\n",
    "![包含以及不包含 $1 \\times 1$ 卷积层的残差块](img/resnet-block.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[不同的残差块](https://www.bilibili.com/video/BV1bV41177ap/?share_source=copy_web&vd_source=a7ae9163cb2cd121bfd86ea1f4ecd2ef&t=416)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[ResNet 块](https://www.bilibili.com/video/BV1bV41177ap/?share_source=copy_web&vd_source=a7ae9163cb2cd121bfd86ea1f4ecd2ef&t=497)**\n",
    "- **高宽减半**ResNet块（步幅 2）\n",
    "- 后接多个**高宽不变**的 ResNet 块\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ResNet 架构**\n",
    "- 类似 VGG 和 GoogLeNet 的总体架构\n",
    "- 但替换成了 ResNet 块\n",
    "\n",
    "![ResNet-18 架构](img/resnet18.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [GluonCV Model Zoo](https://www.bilibili.com/video/BV1bV41177ap/?share_source=copy_web&vd_source=a7ae9163cb2cd121bfd86ea1f4ecd2ef&t=643)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **总结**\n",
    "- 残差块使得很深的网络更加容易训练\n",
    "  - 甚至可以训练一千层的网络\n",
    "- 残差网络对随后的深层神经网络设计产生了深远影响，**无论是卷积类网络还是全连接类网络**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
