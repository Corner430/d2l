{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **网络中的网络（NiN）**\n",
    "\n",
    "![NiN](https://cdn.jsdelivr.net/gh/Corner430/Picture1/images/20230821110045.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **全连接层的问题**\n",
    "- 卷积层需要较少的参数 $c_i \\times c_0 \\times k^2$\n",
    "- **但卷积层后的第一个全连接层的参数**\n",
    "  - LeNet: $16 \\times 5 \\times 5 \\times 120 + 120 = 48120$\n",
    "  - AlexNet: $256 \\times 5 \\times 5 \\times 4096 + 4096 = 37M$\n",
    "  - VGG: $512 \\times 7 \\times 7 \\times 4096 + 4096 = 102M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NiN块**\n",
    "- 一个卷积层后跟两个全连接层\n",
    "  - 步幅 1，无填充，输出形状跟卷积层输出一样\n",
    "  - 起到全连接层的作用\n",
    "\n",
    "![互相关计算使用了具有3个输入通道和2个输出通道的 $1\\times 1$ 卷积核。其中，输入和输出具有相同的高度和宽度](img/conv-1x1.svg)\n",
    "\n",
    "![NiN块](https://cdn.jsdelivr.net/gh/Corner430/Picture1/images/20230821111528.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NiN架构**\n",
    "- 无全连接层\n",
    "- 交替使用 NiN 块和步幅为 2 的最大池化层\n",
    "  - 逐步减少高宽和增大通道数\n",
    "- 最后使用**全局平均池化层**得到输出\n",
    "  - **其输入通道数是类别数**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NiN Networks**\n",
    "\n",
    "![对比 VGG 和 NiN 及它们的块之间主要架构差异](img/nin.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **总结**\n",
    "- NiN 块使用卷积层加两个 1 x 1卷积层\n",
    "  - 后者对每个像素增加了非线性性\n",
    "- NiN 使用全局平均池化层来替代 VGG 和 AlexNet 中的全连接层\n",
    "  - 不容易过拟合，更少的参数个数"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
