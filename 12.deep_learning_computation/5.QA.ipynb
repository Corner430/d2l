{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **将字符串的离散变量变成one-hot变量时候内存炸掉了怎么办？**\n",
    "\n",
    "将字符串的离散变量转换为one-hot变量时，如果内存使用量过大导致程序崩溃，可以考虑以下几种方法来减少内存占用：\n",
    "\n",
    "1. **批处理处理数据：** 如果一次性处理大量数据，可以尝试将数据分成小批次进行处理。这样可以降低内存使用量，并且在GPU上进行计算时也能够提高效率。\n",
    "\n",
    "2. **使用稀疏矩阵：** 在一些情况下，可能会得到一个非常大的one-hot编码矩阵，其中大多数元素都是零。这种情况下，可以考虑使用稀疏矩阵表示，例如`scipy.sparse`库中的CSR或CSC格式，以减少内存占用。\n",
    "\n",
    "3. **降低维度：** 如果字符串的离散变量有很多不同的取值，可能会导致one-hot编码矩阵非常大。你可以考虑将变量的维度降低，例如只保留出现频率较高的取值，或者使用一些特征选择方法来选择最重要的取值。\n",
    "\n",
    "4. **使用Embedding层：** 对于大规模的离散变量，使用Embedding层通常比使用one-hot编码更有效。Embedding层将离散变量映射到一个低维空间，可以在保留信息的同时减少内存占用。\n",
    "\n",
    "5. **数据预处理：** 在处理数据之前，可以对数据进行预处理，例如将字符串变量编码为数字编码，然后再转换为one-hot编码。这可以减少字符串变量的种类，从而降低内存使用。\n",
    "\n",
    "6. **分布式计算：** 如果有大量数据需要处理，可以考虑使用分布式计算框架（如Dask、Ray等）来分散计算负载，从而减少单机内存压力。\n",
    "\n",
    "选择合适的方法取决于你的数据规模、计算资源以及问题的特点。通过组合使用这些方法，可以有效地减少内存使用，使得处理字符串的离散变量变得更加可行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    "\n",
    "#### **`forward` 方法为什么不需要调用？**\n",
    "**`net(X)`实际上是`net.__call__(X)`的简写**\n",
    "\n",
    "在 PyTorch 中，神经网络模型的 `forward` 方法是被**自动调用的。这是因为 `nn.Module` 类在内部已经定义了这个方法**，你只需要在你的自定义模型类中重写它，PyTorch 就会在进行前向传播时自动调用该方法。\n",
    "\n",
    "**可以自己调用，例如`net.forward(x)`**\n",
    "\n",
    "当你调用模型实例（比如 `model(input_data)`）时，**实际上是在调用模型类的 `__call__` 方法**，而这个方法会自动调用 `forward` 方法。这样做的好处是，你在定义模型类时只需要专注于描述网络的架构和操作流程，而无需手动调用 `forward`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
