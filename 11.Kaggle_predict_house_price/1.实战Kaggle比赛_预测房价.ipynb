{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实战 Kaggle 比赛：预测房价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现几个函数来方便下载数据\n",
    "\n",
    "# 导入必要的库\n",
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "# 定义数据存储信息\n",
    "DATA_HUB = dict()  # 数据源字典，存储文件名到下载URL和SHA-1哈希值的映射\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'  # 基础数据下载URL前缀\n",
    "\n",
    "\n",
    "def download(name, cache_dir=os.path.join('..', 'data')):\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名\"\"\"\n",
    "\n",
    "    # 检查文件名是否存在于数据源字典中\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}\"\n",
    "\n",
    "    # 获取文件的下载URL和SHA-1哈希值\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "\n",
    "    # 确保缓存目录存在，不存在则创建\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    # 生成本地文件路径\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "\n",
    "    # 如果本地文件已存在\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()  # 创建SHA-1哈希对象\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)  # 逐块读取文件内容\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)  # 更新哈希值\n",
    "        # 比较计算得到的哈希值与预定义哈希值是否相等\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # 命中缓存，返回文件路径\n",
    "\n",
    "    # 如果文件不存在或哈希值不匹配，进行下载\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)  # 发起HTTP GET请求\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)  # 将下载内容写入文件\n",
    "    return fname  # 返回下载的文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# 使用pandas读入并处理数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "DATA_HUB['kaggle_house_train'] = (DATA_URL + 'kaggle_house_pred_train.csv',\n",
    "                                  '585e9cc93e70b39160e7921475f9bcd7d31219ce')\n",
    "\n",
    "DATA_HUB['kaggle_house_test'] = (DATA_URL + 'kaggle_house_pred_test.csv',\n",
    "                                 'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')\n",
    "\n",
    "train_data = pd.read_csv(download('kaggle_house_train'))\n",
    "test_data = pd.read_csv(download('kaggle_house_test'))\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
      "0   1          60       RL         65.0       WD        Normal     208500\n",
      "1   2          20       RL         80.0       WD        Normal     181500\n",
      "2   3          60       RL         68.0       WD        Normal     223500\n",
      "3   4          70       RL         60.0       WD       Abnorml     140000\n"
     ]
    }
   ],
   "source": [
    "# 前两个和最后两个特征，以及相应标签（房价）\n",
    "print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在每个样本中，第一个特征是 ID，我们将其从数据集中删除\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有缺失的值替换为相应特征的平均值。通过将特征重新缩放到零均值和单位方差来标准化数据\n",
    "\n",
    "# 获取所有数值型特征的索引\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "\n",
    "# 标准化数值型特征\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# 上述操作使用匿名函数对每个特征列进行标准化，将值减去均值并除以标准差\n",
    "\n",
    "# 填充数值型特征中的缺失值\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "# 上述操作将数值型特征中的缺失值用0来填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 331)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理离散值(字符串)。我们用一次独热编码替换他们\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从pandas格式中提取NumPy格式，并将其转换为张量表示\n",
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values,\n",
    "                              dtype=torch.float32)\n",
    "test_features = torch.tensor(all_features[n_train:].values,\n",
    "                             dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_data.SalePrice.values.reshape(-1, 1),\n",
    "                            dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "loss = nn.MSELoss()\n",
    "in_features = train_features.shape[1]\n",
    "\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(in_features, 1))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**我们更关心相对误差$\\frac{y - \\hat{y}}{y}$**，解决这个问题的一种方法是用价格**预测的对数**来衡量差异\n",
    "\n",
    "> **防止对于价格更高的房子，给予了更多的权重。所以算一个百分比，由于有除法，所以用一下log**\n",
    "\n",
    "当我们在进行回归任务时，我们通常希望我们的预测结果能够与真实的标签尽可能接近。但在现实情况下，由于各种因素，预测值和真实标签之间的差异可能会比较大。有时候，数据中可能还包含一些异常值，这些异常值的出现可能会导致预测误差的不稳定性。\n",
    "\n",
    "**对数变换**是一种常用的技术，可以帮助我们在处理这种情况时更好地进行分析和建模。下面解释一下**为什么对数变换能够有助于减小异常值的影响，以及如何使得预测值和真实标签之间的差异更具线性性质**：\n",
    "\n",
    "1. **减小异常值的影响**：\n",
    "   异常值指的是与其他数据点明显不同的数据点。在回归任务中，如果数据中存在一些异常值，它们可能会影响模型的训练和预测结果，导致模型偏离正常数据的表现。对数变换可以有效地缩小异常值的影响，因为对数变换后，数据中较大的值会被拉近，使其与其他数据更接近。\n",
    "\n",
    "2. **线性性质**：\n",
    "   在某些情况下，对数变换可以使数据更加接近线性关系。线性关系对于建立预测模型非常有利，因为很多机器学习算法都假设数据是线性可分的。当预测值和真实标签之间的关系更加线性时，我们可以更好地应用线性模型来拟合数据，从而提高模型的性能。\n",
    "\n",
    "**总之，通过将预测值和真实标签进行对数变换，我们可以在处理异常值时更加稳健，同时也可以使预测值和真实标签之间的差异更趋向于线性关系**，有助于更好地训练和评估预测模型。这对于建立高质量的回归模型非常重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_rmse(net, features, labels):\n",
    "    \"\"\"\n",
    "    计算对数均方根误差（log RMSE）作为模型性能指标。\n",
    "    \n",
    "    参数：\n",
    "        net (nn.Module): 神经网络模型，用于预测特征 features 的标签\n",
    "        features (torch.Tensor): 输入特征数据\n",
    "        labels (torch.Tensor): 真实标签数据\n",
    "    \n",
    "    返回：\n",
    "        float: 对数均方根误差的标量值\n",
    "    \"\"\"\n",
    "    # 对预测值进行剪裁，确保其不会小于1或大于正无穷大\n",
    "    clipped_preds = torch.clamp(net(features), 1, float('inf'))\n",
    "\n",
    "    # 计算对数均方根误差（log RMSE）\n",
    "    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))\n",
    "\n",
    "    return rmse.item()\n",
    "\n",
    "\n",
    "# 注解：\n",
    "# net: 神经网络模型，用于预测特征 features 的标签\n",
    "# features: 输入特征数据\n",
    "# labels: 真实标签数据\n",
    "# torch.clamp(input, min, max): 对输入的张量进行剪裁，限制其取值范围在 min 和 max 之间\n",
    "# torch.log(input): 计算输入张量的自然对数\n",
    "# torch.sqrt(input): 计算输入张量的平方根\n",
    "# loss: 损失函数，用于计算预测值与真实标签之间的差异\n",
    "# rmse.item(): 将计算得到的对数均方根误差的张量值转换为Python标量值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们的训练函数借助Adam优化器\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    \"\"\"\n",
    "    训练神经网络模型，并评估性能。\n",
    "\n",
    "    参数：\n",
    "        net (nn.Module): 要训练的神经网络模型\n",
    "        train_features (torch.Tensor): 训练集特征数据\n",
    "        train_labels (torch.Tensor): 训练集标签数据\n",
    "        test_features (torch.Tensor): 测试集特征数据\n",
    "        test_labels (torch.Tensor): 测试集标签数据\n",
    "        num_epochs (int): 训练周期数\n",
    "        learning_rate (float): 学习率\n",
    "        weight_decay (float): 权重衰减（L2正则化）系数\n",
    "        batch_size (int): 批量大小\n",
    "    \n",
    "    返回：\n",
    "        train_ls (list): 每个训练周期结束后的训练集对数均方根误差列表\n",
    "        test_ls (list): 每个训练周期结束后的测试集对数均方根误差列表\n",
    "    \"\"\"\n",
    "    train_ls, test_ls = [], []  # 初始化列表以存储训练和测试集的对数均方根误差\n",
    "\n",
    "    # 创建数据迭代器，将训练数据划分为批次\n",
    "    train_iter = d2l.load_array((train_features, train_labels), batch_size)\n",
    "\n",
    "    # 创建 Adam 优化器，用于参数更新\n",
    "    optimizer = torch.optim.Adam(net.parameters(),\n",
    "                                 lr=learning_rate,\n",
    "                                 weight_decay=weight_decay)\n",
    "\n",
    "    # 在每个训练周期内进行训练和评估\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            l = loss(net(X), y)  # 计算损失\n",
    "            l.backward()  # 反向传播计算梯度\n",
    "            optimizer.step()  # 使用优化器更新参数\n",
    "\n",
    "        # 计算并记录训练集的对数均方根误差\n",
    "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
    "\n",
    "        # 如果提供了测试集标签，则计算并记录测试集的对数均方根误差\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(net, test_features, test_labels))\n",
    "\n",
    "    return train_ls, test_ls\n",
    "\n",
    "\n",
    "# 注解：\n",
    "# net: 要训练的神经网络模型\n",
    "# train_features: 训练集特征数据\n",
    "# train_labels: 训练集标签数据\n",
    "# test_features: 测试集特征数据\n",
    "# test_labels: 测试集标签数据\n",
    "# num_epochs: 训练周期数\n",
    "# learning_rate: 学习率\n",
    "# weight_decay: 权重衰减（L2正则化）系数\n",
    "# batch_size: 批量大小\n",
    "# d2l.load_array(data, batch_size): 创建数据迭代器，划分数据为批次\n",
    "# torch.optim.Adam(params, lr, weight_decay): 创建Adam优化器\n",
    "# optimizer.zero_grad(): 清零梯度\n",
    "# l.backward(): 反向传播计算梯度\n",
    "# optimizer.step(): 使用优化器更新参数\n",
    "# log_rmse(net, features, labels): 计算对数均方根误差\n",
    "# train_ls: 每个训练周期结束后的训练集对数均方根误差列表\n",
    "# test_ls: 每个训练周期结束后的测试集对数均方根误差列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K 折交叉验证\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    \"\"\"\n",
    "    获取 k 折交叉验证中的训练集和验证集数据。\n",
    "    \n",
    "    参数：\n",
    "        k (int): 折数\n",
    "        i (int): 当前折索引\n",
    "        X (torch.Tensor): 特征数据\n",
    "        y (torch.Tensor): 标签数据\n",
    "    \n",
    "    返回：\n",
    "        X_train (torch.Tensor): 训练集特征数据\n",
    "        y_train (torch.Tensor): 训练集标签数据\n",
    "        X_valid (torch.Tensor): 验证集特征数据\n",
    "        y_valid (torch.Tensor): 验证集标签数据\n",
    "    \"\"\"\n",
    "    assert k > 1  # 确保折数大于1\n",
    "\n",
    "    fold_size = X.shape[0] // k  # 每折的数据大小\n",
    "    X_train, y_train = None, None  # 初始化训练集数据\n",
    "\n",
    "    # 迭代折数，生成训练集和验证集数据\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)  # 当前折的索引范围\n",
    "        X_part, y_part = X[idx, :], y[idx]  # 当前折的数据\n",
    "\n",
    "        if j == i:  # 当前折是验证集的折\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:  # 训练集的第一个折\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:  # 其他训练集折\n",
    "            X_train = torch.cat([X_train, X_part], 0)\n",
    "            y_train = torch.cat([y_train, y_part], 0)\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "# 注解：\n",
    "# k: 折数\n",
    "# i: 当前折索引\n",
    "# X: 特征数据\n",
    "# y: 标签数据\n",
    "# assert k > 1: 确保折数大于1\n",
    "# fold_size: 每折的数据大小\n",
    "# X_train: 训练集特征数据\n",
    "# y_train: 训练集标签数据\n",
    "# X_valid: 验证集特征数据\n",
    "# y_valid: 验证集标签数据\n",
    "# slice(start, stop): 创建一个切片对象，用于获取数据索引范围\n",
    "# X[idx, :]: 使用切片索引获取数据的特征部分\n",
    "# y[idx]: 使用切片索引获取数据的标签部分\n",
    "# torch.cat(tensors, dim): 沿给定维度拼接张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回训练和验证误差的平均值\n",
    "def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        # 获取第i折的训练和验证数据\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        # 创建模型\n",
    "        net = get_net()\n",
    "        # 训练并返回训练和验证误差"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
