{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **单机多卡并行**\n",
    "- 一台机器可以安装多个 GPU （1-16）\n",
    "- 在训练和预测时，我们将一个小批量计算切分到多个 GPU 上来达到加速目的\n",
    "- 常用切分方案有\n",
    "  - 数据并行\n",
    "  - 模型并行\n",
    "  - 通道并行（数据 + 模型 并行）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **数据并行 vs 模型并行**\n",
    "- 数据并行：将小批量分成 n 块，每个 GPU 拿到完整参数计算一块数据的梯度\n",
    "  - 通常性能更好\n",
    "- 模型并行：将模型分成 n 块，每个 GPU 拿到一块模型计算它的前向和反向结果\n",
    "  - 通常用于模型大到单个 GPU 放不下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[数据并行](https://www.bilibili.com/video/BV1vU4y1V7rd/?share_source=copy_web&vd_source=a7ae9163cb2cd121bfd86ea1f4ecd2ef&t=225)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **总结**\n",
    "- 当一个模型能用单卡计算时，通常使用数据并行拓展到多卡上\n",
    "- 模型并行则用在超大模型上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "### **QA**\n",
    "- 数据并行时 GPU 大小不一样也没关系，我们分配不同的样本就OK"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
