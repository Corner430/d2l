1. [CPU 和 GPU](1.CPU和GPU.ipynb)
    - 如何提升 GPU 和 CPU 的利用率
    - 不要频繁在 CPU 和 GPU 之间传输数据
    - 80% 的论文无法复现
    - resnet不可以用在文本上
2. [TPU 和 其他](2.TPU和其他.ipynb)
    - Google TPU
    - Systolic Array
    - 功耗不是问题，电厂也不缺电
    - 做芯片的风险
    - GPU 和 网络要互相 match
    - **Transformer 非常适合 TPU，都是 Google 家的**
3. [单机多卡并行](3.单机多卡并行.ipynb)
    - 数据并行和模型并行
4. [多 GPU 训练实现](4.多GPU训练实现.ipynb)
    - 数据并行时，每个GPU会得到所有的参数
    - 小批量数据量更大时，学习率也需要稍微提高一些。
    - **计算所需的时间长于同步参数所需的时间，并行化开销的相关性较小时，并行化才能体现出优势**
5. [分布式训练](5.分布式训练.ipynb)
    - batch_size 通常不要大于 10 x class_num
6. [编译器和解释器](6.编译器和解释器.ipynb)
    - 命令式编程和符号式编程
    - 保存模型到磁盘
7. [异步计算](7.异步计算.ipynb)
    - 异步计算
    - 前后端
8. [自动并行](8.自动并行.ipynb)
    - 通常情况下单个操作符将使用所有CPU或单个GPU上的所有计算资源
9. [硬件](9.硬件.ipynb)
    - 值得注意的是，在实践中经常会有这样一个判别：加速卡是为训练还是推断而优化的
    - 设备有运行开销。因此，**数据传输要争取量大次少而不是量少次多。这适用于RAM、固态驱动器、网络和GPU**。
    - **矢量化是性能的关键**
    - **在训练过程中数据类型过小导致的数值溢出可能是个问题（在推断过程中则影响不大）**。
    - **训练硬件和推断硬件在性能和价格方面有不同的优点**。