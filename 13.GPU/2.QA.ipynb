{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度学习项目中，当**显存不够用时，或者调整 `batch_size` 后虽然显存够用但 GPU 利用率很低**时，可以考虑以下策略来优化资源使用和训练效率：\n",
    "\n",
    "1. **调整 Batch Size：** 调整 `batch_size` 是一个常用的策略。较小的 `batch_size` 可以减少显存需求，但可能会增加训练时间。适当的 `batch_size` 取决于你的硬件配置和问题特点。可以尝试逐步增大 `batch_size`，找到一个在显存和性能之间的平衡。\n",
    "\n",
    "2. **使用混合精度训练：** PyTorch 支持混合精度训练，即使用浮点数的低精度（如半精度）来进行训练，从而减少显存占用。你可以使用 `torch.cuda.amp` 模块来实现混合精度训练。\n",
    "\n",
    "3. **减少模型复杂度：** 复杂的模型可能需要更多的显存。尝试减少模型的层数、神经元数量或使用更轻量的模型架构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------\n",
    "\n",
    "**GPU使用率很高，也就是满负荷没关系。主要是看温度，最好不要长时间超过80℃**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在使用GPU进行训练时，将数据移动到GPU的时机对于性能和内存效率都是重要的**。通常，将数据移动到GPU应该在数据加载和训练循环之间的某个时刻进行。以下是两种常见的方法：\n",
    "\n",
    "1. **在数据加载之后，训练循环之前：** 这是一种常见的做法。在数据加载时，将数据加载到CPU，并在数据加载完成后将其移动到GPU。这可以确保在训练循环中数据已经在GPU上，从而减少数据传输延迟。\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 循环加载数据和训练\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        # 将数据移动到GPU\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 在GPU上进行训练\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "2. **在数据加载时将数据移动到GPU：** 你也可以在数据加载时将数据移动到GPU上，然后在训练循环中直接使用已在GPU上的数据。这样可以减少内存占用，但需要确保GPU内存足够容纳所有数据。\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 创建数据加载器，将数据加载到GPU上\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "\n",
    "# 循环加载数据和训练\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        # 在GPU上进行训练\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "```\n",
    "\n",
    "在选择何时将数据移动到GPU时，应该根据具体情况来做出决策。如果内存有限，你可以在加载数据时逐批将数据移动到GPU。如果内存充足，你也可以在数据加载之后一次性将所有数据移动到GPU。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
